# ğŸ  Ev FiyatÄ± Tahmin Modeli - DoÄŸrusal Regresyon Analizi

## ğŸ“‹ Proje AÃ§Ä±klamasÄ±

Bu Jupyter Notebook projesi, ev fiyatlarÄ±nÄ± tahmin etmek iÃ§in **doÄŸrusal regresyon** (Linear Regression) modellerini kullanan bir makine Ã¶ÄŸrenmesi Ã§alÄ±ÅŸmasÄ±dÄ±r. Proje, farklÄ± regresyon algoritmalarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rarak en iyi performansÄ± gÃ¶steren modeli belirlemeye yÃ¶neliktir.

---

## ğŸ“Š Veri Seti

**Dosya:** `house_price_regression_dataset.csv`

**Veri Seti Ã–zellikleri:**
- **Toplam Ã–rnek:** 1000 ev
- **Toplam Ã–zellik:** 7 tahmin deÄŸiÅŸkeni + 1 hedef deÄŸiÅŸken

**Ã–zellikler (Features):**
| Ã–zellik | AÃ§Ä±klama | Veri TÃ¼rÃ¼ |
|---------|----------|----------|
| **Square_Footage** | Evin metrekare cinsinden alanÄ± | int64 |
| **Num_Bedrooms** | Yatak odasÄ± sayÄ±sÄ± | int64 |
| **Num_Bathrooms** | Banyo sayÄ±sÄ± | int64 |
| **Year_Built** | Evin yapÄ±m yÄ±lÄ± | int64 |
| **Lot_Size** | Arsa bÃ¼yÃ¼klÃ¼ÄŸÃ¼ | float64 |
| **Garage_Size** | Garaj kapasitesi | int64 |
| **Neighborhood_Quality** | Mahalle kalitesi puanÄ± | int64 |

**Hedef DeÄŸiÅŸken (Target):**
- **House_Price** ğŸ¯ - Ev fiyatÄ± (tahmin edilecek deÄŸer)

**Veri Kalitesi:**
- âœ… Eksik veri yok (Missing values: 0)
- âœ… Ã‡ift kayÄ±tlÄ± veri yok (Duplicates: 0)
- âœ… Veri tam ve temiz

---

## ğŸ”§ KullanÄ±lan Teknolojiler & KÃ¼tÃ¼phaneler

```python
pandas           # Veri iÅŸleme ve analizi
numpy            # SayÄ±sal hesaplamalar
matplotlib       # Veri gÃ¶rselleÅŸtirmesi
seaborn          # Ä°statistiksel grafikler
scikit-learn     # Makine Ã¶ÄŸrenmesi modelleri
```

**Python Versiyonu:** 3.7+

---

## ğŸ“ˆ Proje AdÄ±mlarÄ±

### 1ï¸âƒ£ Veri YÃ¼kleme ve KeÅŸfetme (EDA)

```python
# Verileri yÃ¼kleme
df = pd.read_csv("house_price_regression_dataset.csv")

# Veri inceleme
df.head()        # Ä°lk 5 satÄ±r
df.shape         # (1000, 8)
df.info()        # Veri tÃ¼rleri ve bilgileri
df.describe()    # Ä°statistiksel Ã¶zet
df.isnull().sum() # Eksik deÄŸer kontrolÃ¼
df.duplicated().sum() # Ã‡ift kayÄ±t kontrolÃ¼
```

**Ã‡Ä±ktÄ±:** Veri set temiz ve 1000x8 boyutlarÄ±nda

---

### 2ï¸âƒ£ Korelasyon Analizi

```python
# Heatmap ile korelasyon gÃ¶rselleÅŸtirmesi
sns.heatmap(df.corr(), annot=True)
plt.show()

# YÃ¼ksek korelasyonlu Ã¶zellikler tespit etme
def corelletion_drop(df, threshold):
    corr = df.corr()
    liste = []
    for i in range(len(corr.columns)):
        for j in range(i):
            if abs(corr.iloc[i,j]) > threshold:
                liste.append(corr.columns[i])
    return liste

# 0.60 eÅŸik deÄŸerinin Ã¼zerindeki korelasyonlar
high_corr = corelletion_drop(X_train, threshold=0.60)
# SonuÃ§: [] (Multicollinearity sorunu yok âœ…)
```

**Bulgular:**
- Ã–zellikler birbirleriyle dÃ¼ÅŸÃ¼k korelasyon gÃ¶steriyor
- Multicollinearity sorunu yok
- TÃ¼m Ã¶zellikler modelde kullanÄ±labilir

---

### 3ï¸âƒ£ Veri Ã–n Ä°ÅŸleme (Preprocessing)

```python
# Hedef deÄŸiÅŸken ile Ã¶zellikler ayrÄ±lmasÄ±
X = df.drop("House_Price", axis=1)  # Tahmin deÄŸiÅŸkenleri
y = df["House_Price"]                # Hedef deÄŸiÅŸken

# Train-Test AyrÄ±mÄ± (80-20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Normalizasyon (StandardScaler)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**Ä°ÅŸlemler:**
- âœ… Train-Test AyrÄ±mÄ±: 80% eÄŸitim, 20% test
- âœ… Normalizasyon: StandardScaler ile Ã¶lÃ§ekleme
- âœ… Random State: 42 (tekrarlanabilirlik)

---

### 4ï¸âƒ£ Model EÄŸitimi ve DeÄŸerlendirmesi

DÃ¶rt farklÄ± regresyon modeli kullanÄ±lmÄ±ÅŸtÄ±r:

#### **A) Linear Regression (DoÄŸrusal Regresyon)**

```python
regression = LinearRegression()
lin_model = regression.fit(X_train_scaled, y_train)
y_pred = lin_model.predict(X_test_scaled)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)      # 101,434,798.51
print("Mean Squared Error:", mse)       # 101,434,798.51
print("R2 Score:", r2)                  # 0.9984
```

**SonuÃ§:** 
- MAE: 101,434,798.51
- MSE: 101,434,798.51
- RÂ² Score: **0.9984** âœ…

---

#### **B) Ridge Regression (Ridge DÃ¼zenleme)**

```python
ridge = Ridge()
lin_model = ridge.fit(X_train_scaled, y_train)
y_pred = lin_model.predict(X_test_scaled)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)      # 8,241.59
print("Mean Squared Error:", mse)       # 102,480,990.01
print("R2 Score:", r2)                  # 0.9984
```

**SonuÃ§:**
- MAE: 8,241.59 â­
- MSE: 102,480,990.01
- RÂ² Score: **0.9984** âœ…

---

#### **C) Lasso Regression (Lasso DÃ¼zenleme)**

```python
lasso = Lasso()
lin_model = lasso.fit(X_train_scaled, y_train)
y_pred = lin_model.predict(X_test_scaled)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)      # 8,174.75
print("Mean Squared Error:", mse)       # 101,436,558.18
print("R2 Score:", r2)                  # 0.9984
```

**SonuÃ§:**
- MAE: 8,174.75 â­â­
- MSE: 101,436,558.18
- RÂ² Score: **0.9984** âœ…

---

#### **D) ElasticNet Regression (Elastik Net DÃ¼zenleme)**

```python
elastic_net = ElasticNet()
lin_model = elastic_net.fit(X_train_scaled, y_train)
y_pred = lin_model.predict(X_test_scaled)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)      # 75,137.54
print("Mean Squared Error:", mse)       # 7,545,488,911.95
print("R2 Score:", r2)                  # 0.8829
```

**SonuÃ§:**
- MAE: 75,137.54
- MSE: 7,545,488,911.95
- RÂ² Score: **0.8829** âš ï¸ (Daha dÃ¼ÅŸÃ¼k)

---

## ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rma Tablosu

| Model | MAE | MSE | RÂ² Score | SonuÃ§ |
|-------|-----|-----|----------|-------|
| **Linear Regression** | 101.43M | 101.43M | 0.9984 | Ä°yi |
| **Ridge** | 8,241.59 | 102.48M | 0.9984 | â­ Ã‡ok Ä°yi |
| **Lasso** | 8,174.75 | 101.43M | 0.9984 | â­â­ En Ä°yi |
| **ElasticNet** | 75,137.54 | 7.55B | 0.8829 | DÃ¼ÅŸÃ¼k |

---

## ğŸ“ Metrikler AÃ§Ä±klamasÄ±

### **MAE (Mean Absolute Error)**
- Tahmin hatalarÄ±nÄ±n ortalama mutlak deÄŸeri
- **FormÃ¼l:** $MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$
- Daha dÃ¼ÅŸÃ¼k = Daha iyi
- Birim: AynÄ± birim (bu durumda $)

### **MSE (Mean Squared Error)**
- Tahmin hatalarÄ±nÄ±n karesi ortalamasÄ±
- **FormÃ¼l:** $MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$
- Daha dÃ¼ÅŸÃ¼k = Daha iyi
- BÃ¼yÃ¼k hatalarÄ± daha aÄŸÄ±r penalize eder

### **RÂ² Score (R-Kare)**
- Model aÃ§Ä±klayÄ±cÄ±lÄ±ÄŸÄ± (0 ile 1 arasÄ±nda)
- **FormÃ¼l:** $R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$
- 1.0 = MÃ¼kemmel tahmin
- 0.5 = Orta seviye tahmin
- 0.0 = KÃ¶tÃ¼ tahmin

---

## âœ¨ SonuÃ§lar ve Ã–neriler

### ğŸ† **En Ä°yi Model: Lasso Regression**

**Neden Lasso?**
- âœ… En dÃ¼ÅŸÃ¼k MAE: 8,174.75
- âœ… YÃ¼ksek RÂ² Score: 0.9984
- âœ… Ã–zellik seÃ§imi yaparak modeli basitleÅŸtirir
- âœ… Overfitting riskini azaltÄ±r

### ğŸ¥ˆ **Ä°kinci En Ä°yi: Ridge Regression**
- Benzer performans (RÂ² = 0.9984)
- TÃ¼m Ã¶zellikleri korur
- Daha stabil tahminler

### âš ï¸ **ElasticNet Uygun DeÄŸil**
- DÃ¼ÅŸÃ¼k RÂ² Score: 0.8829
- YÃ¼ksek MSE: 7.55 Milyar
- Bu veri seti iÃ§in uygun deÄŸil

---

## ğŸš€ Projeyi Ã‡alÄ±ÅŸtÄ±rma

### Gereksinimler
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### AdÄ±mlar
1. `house_price_regression_dataset.csv` dosyasÄ±nÄ± proje klasÃ¶rÃ¼ne yerleÅŸtirin
2. `ilk_linear_regression_denemesi.ipynb` dosyasÄ±nÄ± aÃ§Ä±n
3. Jupyter Notebook'da sÄ±rasÄ±yla hÃ¼creleri Ã§alÄ±ÅŸtÄ±rÄ±n (Shift+Enter)
4. Grafikler ve sonuÃ§larÄ± inceleyin

---

## ğŸ“ Dosya YapÄ±sÄ±

```
â”œâ”€â”€ ilk_linear_regression_denemesi.ipynb
â”œâ”€â”€ house_price_regression_dataset.csv
â””â”€â”€ README.md (bu dosya)
```

---

## ğŸ’¡ Ã–nemli Notlar

- **Veri Kalitesi:** Temiz ve tam veri (outlier/missing value yok)
- **Korelasyon:** Ã–zellikler birbirleriyle dÃ¼ÅŸÃ¼k korelasyon gÃ¶steriyor
- **Tekrarlanabilirlik:** `random_state=42` ile sonuÃ§lar aynÄ± kalÄ±r
- **Normalizasyon:** StandardScaler ile tÃ¼m Ã¶zellikler 0-1 aralÄ±ÄŸÄ±nda
- **Model SeÃ§imi:** Lasso tercih edilir Ã§Ã¼nkÃ¼ daha basit ve etkin

---

## ğŸ”® Gelecek Ä°yileÅŸtirmeler

- [ ] Polinom Regresyon testi
- [ ] Feature Importance analizi
- [ ] Cross-Validation uygulanmasÄ± (K-Fold)
- [ ] Hiperparametre optimizasyonu (GridSearchCV)
- [ ] Model tuning ve fine-tuning
- [ ] Outlier detection ve removal
- [ ] Feature engineering
- [ ] Model deployment (Web API olarak)

---

## ğŸ“š Kaynaklar

- [Scikit-learn Linear Regression Docs](https://scikit-learn.org/stable/modules/linear_model.html)
- [Ridge, Lasso, ElasticNet](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification)
- [Model Evaluation Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)

---

**Tarih:** 2024 | **Dil:** Python 3.7+ | **Versiyon:** 1.0 | **Durum:** âœ… TamamlandÄ±
